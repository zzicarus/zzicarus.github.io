# CV 复习

`目录`

[TOC]



# 引言

## 格式塔心理


- 理解每条意思，能简单解释；能够背下来几条并解释
	- Law of Proximity (相近 距离上closer) 当多个元素在空间上彼此靠得更近时，人们会倾向于将这些靠近的元素视为一组或一个整体，而不是单独的个体。
	- Law of Similarity (相似)  人们倾向于将外观相似的元素（颜色、形状、大小等）归为同一类，即使它们并不在一起。
	- Law of Good Continuation (连续)  倾向于延续之前隐含的方向
		- 在一张图片中，如果两条曲线自然延续，而不是突然中断，人们会倾向于将它们视为同一条线。
	- Law of Closure (封闭)  人们倾向于补全一个物体的轮廓或者空洞
	- Law of Prägnanz(goodform) 人们倾向于以最简单、最对称的方式感知事物，即复杂的形状会被组织为简单的形式。
	- Law of Figure/Ground 人们倾向于将视野中的图像分为前景（图形）和背景，前景是关注的主体，背景则是附属部分。

## 计算机视觉从处理层次上看

可分为三个阶段，每个阶段会举例 2 个具体任务

![image-20241224190702441](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202412241907593.png)

- Low-level vision/ early vision
	- 提出基本特征
		- 边缘检测
		- 图像去噪

- Middle-level vision
	- 分割
	- 拟合

- High-level vision
	- 3D 重建
	- 场景理解


# 二值图像

## 几何特性

常见的几何特性及含义

![image-20241224191439168](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202412241914311.png)

## 投影计算

- 投影计算一水平、垂直
- 知道定义与基本原理，给例子会计算

## 连通区域

![image-20241224192241218](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202412241922334.png)

### 连通分量标记算法（贯序）

![image-20241224192211485](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202412241922637.png)

### 区域边界跟踪算法

![image-20241224192516724](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202412241925842.png)

# 边缘检测

## 模板卷积

给一个图像与一个模板，会计算卷积结果

![image-20241224192654547](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202412241926647.png)

## Origin Of Edges

四种最主要的不连续 (discontinuity)

1. **亮度不连续性 (Discontinuity in Intensity)**
- 两个区域间的亮度值发生显著变化，例如黑白边界。
2. **颜色不连续性 (Discontinuity in Color)**
- 不同颜色区域间的过渡，例如红色和蓝色区域的边界。
3. **深度不连续性 (Discontinuity in Depth)**
- 三维场景中不同物体表面深度的差异，例如遮挡区域的边界。
4. **表面法向量不连续性 (Discontinuity in Surface Normal)**
- 表面方向发生急剧变化，例如曲面与平面的连接处。

## 边缘检测的基本思想
边缘检测的目标是检测图像中像素值发生显著变化的位置，即边缘。

基本步骤包括：

1. 平滑 (Smoothing)：降低噪声对边缘检测的干扰。
2. 求导 (Differentiation)：计算图像梯度以检测变化。
3. 定位 (Localization)：通过阈值化或非极大值抑制精确确定边缘位置。

## 基于一阶的边缘检测（有哪些）

Roberts交叉算子、Sobel算子、Prewitt算子

<img src="https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202412241931403.png" alt="image-20241224193138280" style="zoom:50%;" />

## 基于二阶的边缘检测（有哪些）

二阶方法通过检测梯度的变化（梯度的导数）定位边缘，特别适用于检测零交叉点。

### Laplacian 算子

![image-20241224193418966](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202412241934055.png)

### LoG 算子 (Marr&Hildreth 算子）：为到么要加 G

**原理**：先用高斯滤波器对图像进行平滑处理，再使用 Laplacian 算子检测边缘。

**为什么要加 G**：

- 高斯滤波器用于平滑图像，去除噪声对边缘检测的干扰，提升边缘检测的稳定性和鲁棒性。



## Canny 边缘检测

> 理解 Canny 边缘检测方法，能写出该方法的关键步骤，能说出其中两个阈值的意义

1. 用高斯滤波器平滑图像

2. 用一阶偏导有限差分计算梯度幅值和方向.

3. 对梯度幅值进行非极大值抑制（NMS） ．

	1. ![image-20241226181829422](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202412261818566.png)

4. 用双阈值算法检测和连接边缘．

  1. **高阈值**：过滤出强边缘，确保检测的边缘显著。
  2. **低阈值**：确保连接性，避免因边缘断裂导致信息丢失。

  <img src="https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202412241941874.png" alt="image-20241224194139759" style="zoom:33%;" />

# 曲线

## Hough变换

- [详解 Hough 变换（基本原理与直线检测） - Gaowaly - 博客园](https://www.cnblogs.com/Gaowaly/p/18327804)
- [OpenCV: Hough Line Transform](https://docs.opencv.org/3.4/d9/db0/tutorial_hough_lines.html)

- 用来解决什么问题？ 

	- ==重要的形状检测技术==
	- Hough 是基于投票 **(Voting)** 原理的参数估计方法
	- 图像中每一点对参数组合进行表决，赢得多数票的参数组合为胜者（结果）．
- 基本思想
- 会用图示解释 Hough 变换做直线检测的具体原理
  ![image-20241225103058814](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202412251030995.png)
  - 
- 对于直线检测或圆的检测，能写出算法基本步骤  

  1. 适当地量化参数空间（合适的精度即可）．
  2. 假定参数空间的每一个单元都是一个累加器，把累加器初始化为零．
  3. 对图像空间的每一点，在其所满足的参数方程对应的累加器上加 **1** ．
  4. 累加器阵列的最大值对应模型的参数．
- 圆弧检测
  ![image-20241225104507925](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202412251045096.png)
- 参数空间离散化，精度低或高分别有什么不好？

  - **精度过低：**
  	- 累加器单元过大，多个不同的形状可能投票到同一单元，造成识别模糊。
  	- 无法检测细微变化。
  - **精度过高：**
  	- 累加器单元过小，投票分散，累加值较低，难以检测到明显形状。
    - 增加计算量，降低效率。

# 局部特征

## Harris 角点检测

![image-20241225105836669](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202412251058879.png)

- Basic Idea
	![image-20241225110122797](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202412251101963.png)
	
- 会推导这条公式

![image-20241217191546199](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202412171915292.png)

![image-20241224201520352](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202412242015487.png)

- 理解 M 矩阵两个特征值的含义。两个特征值代表的含义其与 Harris 角点关系是什么？
	- $\lambda_1 和\lambda_2表示变化最剧烈、缓慢的方向$

- 知道 Harris 对旋转不变性、灰度仿射不变性、尺度不变性的定性判断
	- Partial invariance to affine intensity change
		- Only derivatives are used => invariance to intensity shift I ® I + b

## SIFT 描述子的计算

==这里课程只要求对decriptor进行计算，额外的拓展可见[Overview | SIFT Detector](https://www.youtube.com/watch?v=KgsHoJYJ4S8)==

> **优点：**
>
> 1.  具有尺度、 旋转、 亮度不变性
>
> 2.  在局部块上有⾼度独特和描述性

 **invariant to** **translation , rotation**, **scale**, and other imaging parameters

- Full version 的基本计算步骤

<img src="https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202412251150791.png" alt="image-20240107170740388" style="zoom:50%;" />

![](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202412251158421.png)



- 为什么使用梯度信息？好处？
  - 梯度信息可以表示边缘信息，并且对于光照变化具有较强的适应能力
  - 梯度信息反映了图像中像素值变化的方向和强度，能很好地捕捉局部纹理特征和边缘信息。
  
- 如何实现旋转不变的？
  - 根据其主要梯度方向(dominant gradient orientation)旋转 patch, 这样可以使他处于规范方向
  - **确定主方向：** 找出方向直方图中的主峰，作为关键点的主方向
  - **方向对齐：** 在描述子构建时，将所有梯度方向相对于主方向进行旋转对齐，消除由于图像旋转引起的特征差异
- 如何实现光照不变
	- 计算feature vector时，进行了一次归一化Normalized处理，卡阈值之后又进行了一次归一化处理
		- 在构建描述子时，对梯度幅值进行归一化，确保特征向量对整体光照变化具有鲁棒性。
		- **对大梯度抑制：** 为避免局部光照异常（如强光源）对特征的影响，SIFT会截断过大的梯度值。
	
- 尺度不变
	- 金字塔模型，对多种尺度都能进行检测 DoG 高斯差分



## 大致理解实现尺度不变的原理（需要自己总结）

- **高斯金字塔：** 在多尺度下表示图像。
- **差分高斯金字塔：** 快速定位在不同尺度下的显著特征点。
- **尺度空间检测：** 确保特征点对图像缩放具有鲁棒性。
- **描述子提取：** 在关键点的最佳尺度上提取特征，归一化消除尺度影响。

# 图像拼接

## 图像拼接 ？

实现两张图像自动拼接的几个基本步骤

1. 特征点检测：在每张图像中检测出一些有意义的特征点，例如角点、边缘点或纹理关键点。
2. 特征点描述：对于每个特征点，计算其局部特征描述子，例如\*SIFT\*、SURF\*或ORB\*等。
3. 特征点匹配：对于不同图像之间的特征点，通过比较其特征描述子，找到最佳的匹配对。
4. 图像对齐：根据特征点的匹配关系，计算图像之间的几何变换，例如平移、旋转和缩放，以使其对齐。
5. 图像融合：将对齐后的图像进行颜色校正和融合，以创建无缝连接的全景图像。

![image-20240107181501952](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202412251207839.png)

## 图象金字塔

[（二十六）图像金字塔----高斯和拉普拉斯 - 知乎](https://zhuanlan.zhihu.com/p/80362140)

- 如何理解拉普拉斯金字塔？从频率角度看，是什么？
	- 拉普拉斯金字塔是一种图像表示方法，它通过逐级减去图像的低频成分，保留图像的细节信息（高频成分）
		![image-20241226184425659](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202412261844788.png)
	- **带通滤波器：**
		- 每一层的拉普拉斯金字塔图像可以看作是在特定频率范围内（带通）的成分。

- 如何理解高斯金字塔？从尺度角度看，是什么？
	- 多分辨率的图像表示方法，通过逐级对图像进行高斯模糊和下采样，得到一系列分辨率逐渐降低的图像
		- 先高斯模糊再下采样

	- 高斯金字塔通过调整模糊程度和分辨率，将图像分解为不同尺度的表示
		- 去高频保低频


| 特性             | 拉普拉斯金字塔               | 高斯金字塔                       |
| ---------------- | ---------------------------- | -------------------------------- |
| **表示内容**     | 高频细节（高频分量）         | 多尺度的完整图像（包含低频分量） |
| **构建方式**     | 高斯金字塔相邻层相减         | 高斯模糊 + 下采样                |
| **从频率角度看** | 带通滤波器，保留细节信息     | 低通滤波器，逐步去除高频信息     |
| **从尺度角度看** | 细节分离，适合特征检测和压缩 | 多尺度表示，适合整体特性分析     |
| **典型应用**     | 图像压缩、特征分析           | 特征点检测、多尺度分析           |

## RANSAC

- Generally speaking, 可以解决什么样的问题？
	- **鲁棒估计算法**，主要用于从一组包含**异常值（outliers）**的数据中估计模型参数。

- 理解过程的核心思想
	- 通过随机采样的方式，从数据中找到支持度最高的模型参数，并以此剔除异常值（outliers）。

- 优点
  - 可以估计迭代的次数
  	- 如何做要理解
  - 不需要假设异常值的分布
  
- 基本步骤（迭代 Loop)

	- **随机抽样**：首先从数据集中随机选择一定数量的数据点来构建候选模型。
	- **模型拟合**：使用选定的数据点来拟合模型（例如，拟合一条直线以适应选定的两个点）。
	- **内点筛选**：对于剩余的数据点，检查它们是否与当前拟合的模型一致。如果一个数据点与当前模型一致（例如，距离在一定阈值内），则将其标记为“内点”，否则标记为“外点”。
	- **评估模型**：计算模型适应数据的度量，例如符合内点的数量。
	- **重复迭代**：重复上述步骤多次（通常是几十甚至几百次），选择产生最大内点数的模型。
	- **模型验证**：最终模型需要经过验证，以确保其在整个数据集上的性能。

- outliner 点比例给定的情况下，则 k 次采样（迭代）后计算成功的概率是？
  ![image-20241226185901327](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202412261859455.png)

  - w=0.8, 模型取点数为3，问最少要取几个点才能保证概率>95%RANSEC收敛

- 思考：与 Hough 变换有什么共同之处？

	- **解决目标：** 都能从含有大量异常值的数据中找到目标模型。
	- **通过投票机制处理异常值：**
		- RANSAC 的“支持点数”类似于 Hough 变换的投票计数。
		- 两者都通过最大支持度来确定最佳模型。
	- **适用场景：**
		- 都用于模型拟合和特征提取。

- 不同

	- 保证代价（迭代次数，计算耗时等）不过大的基础上，只能处理外点比例不高的数据——In contrast, 

		Hough变换能处理外点比例很高的数据集合


# 主元分析和人脸识别

## PCA

- 基本思想是最小化什么？
	- 两种理解思路
		- 最小化投影误差
		- 最大化数据之间的方差

- 什么样的数据点用 PCA 会比较有效？
	- 数据点之间具有**强相关性**（线性相关）的情况

	- 数据的变化主要集中在少数几个方向上（即存在主方向）

- 下面这个优化标函数的推导<img src="https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202412261905138.png" alt="image-20241226190509026" style="zoom:25%;" />

![image-20241226190812752](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202412261908952.png)

- 关于选取多少个特征向量构建了空间，常用什么方法？

	- 
- PCA 分析与 DCT 离散余弦变换的相同之处？不同之处？
  - 相同
  	- 都用于**数据降维和信息压缩**。
  	- 都将数据从原始空间变换到另一个空间以保留主要特征。
  - 不同
    - DCT 使用局部特征
    - PCA 使用原始向量（全局特征）表示某一维度的特征
- 怎么理解降维之后，还能重构升维？

	- PCA 的降维和升维本质是一个线性映射过程：

		1. **降维：** 将数据 XXX 投影到主成分子空间 WWW 上。 $X_{Low} = W^T*X$

		1. **升维（重构）：** 使用低维数据在原空间的基向量 WWW 上重建近似的原始数据： $X_{reconstructed}=WX_{Low}$

## Eigenface

- "Eigenface" 是什么？ 
	- 基于主成分分析 (PCA) 的人脸特征提取和识别方法。它将人脸图像表示为主成分的线性组合，即以特定基向量（称为 eigenfaces）表示所有训练样本的特征。

- Eigenface 人脸识识方法的基本步骤
	- 获得人脸图像的训练集，通常为整个人脸数据库；
	- 对所有人脸图像作归一化处理；
	- 通过PCA计算获得一组特征向量(特征脸)。通常一百个特征向量就足够；
	- 将每幅人脸图像都投影到由该组特征脸张成的子空间中，得到在该子空间坐标；
	- 对输入的一幅待测图像，归一化后，将其映射到特征脸子空间中。
	- 然后用某种距离度量来描述两幅人脸图像的相似性，如欧氏距离。

- 写基于 Eigenface 的人脸重构公式（线性加权和）
	- 均值 + 加权和
		![image-20241226191906513](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202412261919645.png) 

- 理解利用人的人脸重构进行人脸检测的原理
  - 如果一幅白噪音图像使用eigenface进行重构，预计结果是？原因是？
  	- **预计结果：** 白噪声图像的重构误差通常很大。
  	- 白噪声图像没有符合人脸特征的模式，无法用 eigenfaces 有效表示。
  	- 投影得到的权重 wiw_iwi 无法有效描述数据特征，重构结果不接近原始噪声
- Eigen-X 利用过程中需要注意什么
	- **特征数量选择：**
		- 过多特征会增加计算复杂度，过少特征会导致信息丢失。
	- **数据对齐和标准化：**
		- 输入数据需进行归一化和对齐处理，减少偏差对主成分的影响。
	- **特征空间的适用性：**
		- Eigen-X 适合用在刚性、模式固定的数据上。

- 还有什么数据适合使用EigenX方式建模
	- 有比较固定的形状，刚性的物体
		- 比如车辆、建筑


# 图像频域和图像分解

## 傅里叶变换

- 基本含义
- 理解低频成分、高频成分

	- **低频成分：**

		- 表示信号的整体趋势或大范围变化。
		- 对应图像中的平滑区域或大块颜色变化。

		**高频成分：**

		- 表示信号中的快速变化或细节信息。
		- 对应图像中的边缘、纹理或噪声。


## 图像分解

- 从图像分解角度，理傅里叶变换的意义

	- **频域分析：**

		- 将图像分解为不同频率的分量，便于分析图像的特性（如纹理、边缘）。

		**图像处理：**

		- 通过过滤频率成分实现图像增强、去噪或压缩。

		**实现分解：**

		- 通过二维傅里叶变换，将图像从空间域转到频域

- 拉普拉斯图像金字塔是如何构建出来的？

	- **生成高斯金字塔：**

		- 对图像进行多次高斯模糊并下采样，得到一系列分辨率递减的图像。

		**计算差分图像：**

		- 在每一层中，用当前层的高斯模糊图像减去下一层上采样后的图像。
		- 差分图像即为拉普拉斯金字塔的每一层。

		**存储金字塔：**

		- 保存差分图像和金字塔底层（最高模糊层）图像。

- 理解拉普拉斯图像金字塔的每一层是带通滤波
  - 反应频带信息通过对频带信息的叠加

# 物体识别

## VisuaI Recognition

- 基本任务大概可以分为些？
	- **图像分类（Image Classification）**
		- 判定输入图像的类别。
		- 输出通常是固定类别标签。
	- **目标检测（Object Detection）**
		- 识别图像中的多个对象，并给出它们的位置（用边界框表示）。
	- **图像分割（Image Segmentation）**
		- 将图像划分为多个区域，每个像素标记为特定类别。
		- 包括语义分割（Semantic Segmentation）和实例分割（Instance Segmentation）
	- **姿态估计（Pose Estimation）**
		- 识别人体或其他物体的关键点位置。
		- 示例：OpenPose。
	- **动作识别（Action Recognition）**
		- 从视频或图像序列中识别出动作类型。
		- 示例：跳跃、跑步、挥手等。
	- **图像生成（Image Generation）**
		- 创建基于输入条件的新图像。
		- 示例：GAN（生成对抗网络）

- 都有哪些挑战因素？
	- **数据问题：**
		- 数据集规模不足（数据量小，类别不平衡）。
		- 数据质量差（噪声、标签错误）。
		- 数据分布不一致（训练集与测试集分布差异）。
	- **环境复杂性：**
		- 光照变化：明暗对比、阴影影响识别。
		- 视角变化：目标可能以不同角度呈现。
		- 目标遮挡：部分目标可能被遮挡。
		- 背景复杂：干扰信息多。
	- **类别泛化：**内部的种类泛化
		- 类别间的相似性：不同类别可能有相似外观（如狼与哈士奇）。

- 理解 Generalization error 中模型带来的 Bias 与 variance ，以及模型复杂度跟overfit, underfit 的关系
	- **欠拟合（Underfitting）：**
		- 原因：模型过于简单，不能充分学习数据特性。
		- 表现：高 Bias，低 Variance。
		- 解决方法：
			- 增加模型复杂度（更多特征、更复杂结构）。
			- 使用更强大的算法。
	- **过拟合（Overfitting）：**
		- 原因：模型过于复杂，过度拟合训练数据中的细节和噪声。
		- 表现：低 Bias，高 Variance。
		- 解决方法：
			- 减少模型复杂度（正则化、Dropout）。
			- 增加训练数据量。
			- 使用早停（Early Stopping）方法。


## 基于 词袋 | BoW 的物体分类

- 图像的BoW （ bag of words ）是指什么意思？
	- 将图像表示为特征词频统计的方法。图像被看作由一组“视觉单词（visual words）”组成的集合。

- 如何构建visual words?
  1. Feature detection and representation 特征的提取和表示
  	1. 使用特征提取算法（如 SIFT、SURF、ORB）提取图像中的局部特征描述子。
  	2. 这些描述子是固定维度的向量，表示局部区域的特征信息。
  2. Codewords dictionary formation 构建词典
  	1. 聚类算法（如 K-means）对从所有训练图像中提取的特征描述子进行聚类
  	2. 聚类的类别数 KKK 决定词典的大小
  3. Image Representation 编码图像
  	1. 对图像中每个局部特征描述子，找到其最近的视觉单词（聚类中心）
  	2. Represent an image with histogram of codebook
  4. Classify an unknown image with its BoW.
- 基本步骤

![image-20241226194346303](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202412261943511.png)


## 基于卷积全局优化的物体分类

- 会简单推导并解含义（ SM = softmax ）

![](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202412171935755.png)

- 这里softmax的作用是什么
- W的矩阵是由什么组成的？含义是什么？

# 光流 Optical flow

- 光流解决的是什么问题？
- 光流三个基本假设是什么？
- 对于以下一个点的约束等式，会自己推导：

![image-20241217194314084](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202412171943150.png)

- 哪些位置的光流比较可靠？为什么？

# 深度学习

## 深度学习

- 怎么理解被称为 end · to · end 的学习？
- 神经网络的学习/训练，数学上本质是求解神经网絡的什么？
- 会写出基于梯度下降法的学习框架·

## BP 反向传播算法

- BP 算法作用是计算什么？理解“梯度下降法"与 BP 算法的关系
- ==重要！==给一个计算公式，会画出计算图，并根给定的初始值计算梯度反向传播的过程 （正向与反向）

## CNN

- 与全连接网络相比， CNN 在哪几个方的做了重要改变？为什么这么改？
- 卷积层的作用是什么？
- 卷积层主要利用两个技巧减少模型参数？
	- 
	- 参数共享

- 自己会计算第一个卷积层的权重 weight 数量
  - 注意：**权重与连接数的差别**
  	- 不同的连接使用的可能是同一个权重 <-> 使用同一个卷积核

## 关于训练

- batch 技巧是指什么？怎么理该方法
- batch normalization 是为了改变优化过程中的什么？
- 基于 动量|Momentum 的 梯度下降法，其主要思想是什么？希望解决优化过程中的什么问题。

## 关于注意力机制

- self-attention 机制主要是对什么样的信息进行建模？
	- 
	- 应用：自然语言处理、语音识别、视觉检测

- 理解 self-attention 机制中的 q/k/v 想代表的含义/意思？
	- q query
	- k 
	- v value
	- attention score   <img src="https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202412241712750.png" alt="image-20241224171235547" style="zoom:33%;" />
		- 加一层softmax对这个score进行归一化
	
- 为什么要加位置编码（ positional encoding ）
	- 

- SeIf-attentiontion 与 CNN 卷积机制的关系？
	- CNN 只考虑感受野中的上下文，是简化的self-attention
	- Self-attention 使用 learnable receptive field
	- CNN 在小样本上表现不错

- Self-attention 与循环神经网络模型（ RNN ）的关系？
	- RNN
		- 依赖于之前的序列，不能并行计算（self-attention可以）
- Self-attentiontion 机制与图神经网络 GNN 的关系？
	- 

# 相机模型

## 理解：景深/光圈/焦距/视场的关系

- 光圈对景深的影响？ 理解原理，会画图解释
- 焦距对 视场 Field Of View 的影响？理解原理，会画图解释

## 理想的针孔相机 (pinhole camera) 模型

- 基本投影公式，并能画图说明，会推导出公式，并写出齐次坐标形式下的透视投影公式（矩阵形式的）
- 有哪几个内参（不包括变参数），会写内参矩阵
- 投影变化：保角？保距？保平行？保共线？
	- 不需要深究

## 齐次坐标系

- 齐次坐标有什么好处？并能举例说明
- 齐次坐标与笛尔坐标会换算
	- PPT 例子
- 给一个刚体变换 Rx + t, 会推导出齐次坐标的矩阵乘法形式

## 畸变

- 径向畸变与切向畸变各是什么原因引起的？
	- 

- 径向畸变常见的有哪两种？
	- 桶形畸变
	- 枕形畸变


## 相机外参

- 外参有哪几个？分别代表什么含义？**齐次坐标下的外参矩阵会写、会推导。**

## 四个坐标系

- 知道相机模型成像过程中涉及的四个坐标系
- 会画图展示内参、外参、畸变参数在成像各阶段中的角色（从真实的世界坐标到图像坐标的）

## 相机定标

基于Homography的相机定标

- 相机定标 camera calibration 的基本思路或思想
- 有哪些优点？
- 基木过程（4 个步骤）
- Homography - 矩阵有几个自由度？求解需要至少几个特征点？
- 根据未知参数的数量，会简单估算需要最少拍几张定标图片

# 立体视觉

## 立体视觉的三角测量基本原理

- 会画 “视差disparity” 的那张图，并自己辅助线推导深度的计算公式。
- 根据计算公式，会分析深度分辨率和哪几个因素有关系？会图解

## 立体视觉的步骤还四个基本步骤

- 简述四个基本步骤(review:How to Do Stereo):Undistortion、Rectification, Correspondence. Reprojection ktriangulation
- Rectification 这个步骤的目的是什么?如果不做 Rectification,有什么不好?
- 怎么理解:通过 Stereo matching 时,可将原来的2D匹配问题,转化为1D匹配问题。

# 结构光三维成像

## 结构光成像系统的组成

## 利用结构光获取三维数据的基本原理

- 会画图,会做辅助线推导公式
- 搞清楚哪些已知,哪些未知

## ICP算法

- 该算法用于解决什么问题?
- 算法的基本步骤

![image-20250107143653457](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202501071437656.png)

# 图像分割

> 这下面的部分在今年的 pg 老师班复习PPT没有

## 基于聚类的图像分割

- 理解用聚类进行图像分割的基本原理。

## 基于 Mean Shift 的图像分割

- 为什么要转化色彩空间，不直接用 RGB 空间
- 基本原理？与 Kernel 密度估计是什么关系？
- 跟 k-means 图像分割相比，有什么好处？

## 基于 k·means 聚类的图像分割

- 理解聚类进行图像分割的基本原理。
- 给定一副图像，能描述如何用 k · means 进行分割的算法基本步骤（除了 k · means 算法本身的几个步骤之外，还自己总结添加 k-means 之前做什么、 k-means 之后做什么）

## 基于 Mean Shift 的图像分割

- 基本原理
- 跟 kmeans 图像分割相比，有什么好处？

