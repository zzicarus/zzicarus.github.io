# Speed and Size

处理器速度  <= 高度相关 =>  寄存器速度

## Memory Technology

### **SRAM**
- value is stored  on a pair of inverting gates
- very fast but takes up more space than DRAM 

![alt text](images/custom-image-2.png)

### **DRAM**
- Value is stored as a charge on capacitor 电容器
- Very small but slower than SRAM (factor of 5 to 10)
- Must periodically be refreshed
- Read contents and write back (destructive read)

Bits in a DRAM are organized as a rectangular array

DRAM accesses an entire row

**Burst mode:** supply successive words from a row with reduced latency (SDRAM)

从一行中连续读取比较快

[数字逻辑](https://note.hobbitqia.cc/Logic/logic07/#dynamic-ram-dram)

!!! quote ""
    高速的口一般是串行的，接口很少  <== 保证多条线同时到达目标

### **Flash**

Nonvolatile semiconductor storage

只能从1写到0，擦除代价大

- NOR flash: bit cell like a NOR gate
    - **Random read/write access**
    - Used for instruction memory in embedded systems
- NAND flash: bit cell like a NAND gate
    - **Denser (bits/area), but block-at-a-time access**
    - Cheaper per GB
    - Used for USB keys, media storage, …
- Flash bits wears out after 1000’s of accesses
    - Not suitable for direct RAM or disk replacement
    - Wear leveling: remap data to less used blocks

### **Disk**

## Memory Hierarchy Introduction

**locality**

- Temporal locality  时间局部性
    - **Items accessed recently** are likely to be accessed again soon
    - e.g., instructions in a loop, induction variables
- Spatial locality   空间局部性
    - Items **near those accessed recently** are likely to be accessed soon
    - E.g., sequential instruction access, array data

- Copy recently accessed (and nearby) items **from disk to smaller DRAM memory**
Main memory

- Copy more recently accessed (and nearby) items **from DRAM to smaller SRAM memory**
Cache memory attached to CPU

cache 在CPU内部

**概念**

![alt text](images/custom-image-4.png)

- `Block` : unit of copying 搬运的最小单位 可能是一个word或者多个word

- `Hit` : If accessed data is present in upper level
    两层：从硬盘到内存，从内存到cache

    - `Hit Time` : The time to **access the upper level** of the memory hierarchy, which includes the time needed to **determine whether the access is a hit** or a miss.

    - `Hit ratio`: hits/accesses

- `Miss` : block copied from lower level
    - `Miss ratio` : misses/accesses = 1 – hit ratio
    - `Miss penalty` :         The time to **replace a block in the upper level** with the corresponding block from the lower level, plus the time to **deliver this block to the processor.**（可能会有"脏数据"需要写回去）

![alt text](images/custom-image-5.png)

## The basic of Cache

> SRAM and DRAM (main memory) 

### Direct mapped

![alt text](images/custom-image-6.png)

**(Block address) modulo (Number of blocks in the cache)**

固定的位置，

**Tag**  区分存放的哪个数据
- Store block address as well as the data
- Actually, only need the high-order bits

**Valid Bits**  这个Block是否为空
Valid bit: 1 = present, 0 = not present
Initially 0


![alt text](images/custom-image-9.png)

??? example "example"
    ![alt text](images/custom-image-7.png)

!!! note "理解cache中的各个位"
    ![alt text](images/custom-image-11.png)
    上面的部分是 Memory address，下面的才是cache中的。这里每一个Block有四个word，需要两位来定位word，每个word有四个字节，需要两位来定位byte，故而`Byte offset = 4`
    

    `index` 在cache中寻找block，其大小由Block num决定
    
    `Offset` 用于去在data中寻址。注意寻址方式，一般是字节寻址。
    
    所以cache实际的size是 data + Tag + Valid
    
    `Tag` 由 memory address 减去 Index、Byte Offset计算

**计算**

Cache : Tag Index Byte offset

`Byte offset`: 根据Block Size计算

`Tag bits`: 64 − (n + m + byte offset)

`Byte Offset` : 根据 `m words/block`计算

`2^n`: cache size, block num

`Index bits` : data size / block size

`m`: index to reference words in block

`Total cache size`: 
Block num(2^n) * (data size + tag size + valid bit)
cache中含有valid bit, tag bit , data bit

block size 其实就是数据

cache的命名不考虑标签和有效位的大小，只考虑数据的大小

??? example "example"
    ![alt text](images/custom-image-8.png)
    ![alt text](images/custom-image-10.png)

**Handling Cache reads hit and Misses**

- Read

- Write
    - write-back: Cause Inconsistent 
    Wrote the data into only the data cache
    
    Strategy ---- write back data from the cache to memory later
    
    - write-through: Ensuring Consistent
    

### Deep Concept

!!! info "引入"
    ![alt text](images/custom-image-13.png)

1-word block
![alt text](images/custom-image-15.png)
#### Block Placement
![alt text](images/custom-image-14.png)


##### Fully Associative 

Block can go anywhere in cache

##### Set Associative

Block can go in **one of a set of places** in the cache. 

**A set** is a group of blocks in the cache.

Block address MOD Number of sets in the cache   也就是针对上面的index在这里会是set index
If sets have n blocks, the cache is said to be **n-way set associative.**  

#### Block identification

基本相同

#### Block replacement

- `Random replacement` - randomly pick any block

- `Least-recently used (LRU)` - pick the block in the set which was least recently accessed

Assumed more recently accessed blocks more likely to be referenced again

**This requires extra bits in the cache to keep track of accesses.**

- `First in,first out(FIFO)`
- Choose a block from the set which was first came into the cache

#### Write Strategy

 **write hit**

- **If the data are written to memory**, the cache is called a **write-through cache**
    - Can always discard cached data - most up-to-date data is in memory
    - Cache control bit: **only a valid bit**
    - memory (or other processors) always have latest data
    - 读取miss不会影响write
- **If the data are NOT written to memory**, the cache is called a **write-back cache**
    - Can`t just discard cached data - may have to write it back to memory
    - Cache control bits:**both valid and dirty bits**
    - much lower bandwidth, since data often overwritten multiple times

**Write stall** 

When the CPU must wait for writes to complete during write through

**Write buffers**

- A **small cache** that can hold a few values waiting to go to main memory. 
- This buffer helps when writes are clustered. 
- 如果一次写入的量很大，很可能超过buffer的容量	

![alt text](images/custom-image-18.png)

- 增加了数据访问的复杂度，需要检测数据是否在write buffer中，否则并行的一IC数据访问读取的是旧数据

**Write miss**

看是否写回到cache中去

- **Write allocate **
The block is **loaded into the cache** on a miss before anything else occurs. 

- **Write around (no write allocate) **
The block is only **written to main memory** 
It is not stored in the cache. 

- **In general, write-back caches use write-allocate , and write-through caches use write-around.**  

#### Designing the Memory system to Support Cache 

![alt text](images/custom-image-19.png)

对主存的加速。单纯的One-word-wide架构，由于对DRAM取数据很耗时，会造成很多时间浪费

!!! note "概念"
	`Bandwidth` 带宽，是一个时钟周期能访问的Bytes数目  $Bandwidth = \frac{Bytes}{CLK}$
	
	`miss penalty` 移动一个Block的代价

**增大 Memory 位宽**

![image-20240521155329202](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202405211553286.png)

**增加Memory数量（类似并行**

`4 banks Interleaved Memory`

![image-20240521155558321](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202405211555404.png)

## Measuring and improving cache performance

The main contents are the following:

1. Measuring cache performance

2. Reducing **cache misses** by **more flexible placement** of blocks

3. Reducing the **miss penalty** using multilevel caches


$$
\text{Average Memory Assess Time (AMAT) = hit time + miss time}\\
\text{= hit rate × Cache time + miss rate ×memory time}
$$

### Measuring

我们使用CPU Time来衡量 how good it works
$$
{CPU\ Time} = \text{CPI * I * CPU cycle time}
\\ =\text{CPU Excution Time} + \text{CPU Memory-stall Time}
$$

$$
\text{CPU Memory-Stall Time} = \text{Read-stall+Write-stall}\\
= \#of\ instructions\text{ * miss ratio * miss penalty}
$$

**For Read**

$\text{Read-stall} = \frac{Read}{Program}*\text{Read miss rate * Read miss penalty}$

**For Write**

$Write-stall = \frac{Write}{Program}*\text{Write miss rate * Write miss penalty} + Write Buffer$

- **If the write buffer stalls are small, we can safely ignore them .**

- **If the cache block size is one word, the write miss penalty is 0.**
- 通常情况下都可以忽略  <== 设计的较好的CPU一般不会满

**一定要注意Write的类型，针对write hit**
Write-through  Write-back
**还有miss的应对**
Write-allocate  Write-around

**计算**

<img src="https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202405211645286.png" alt="image-20240521164455798" style="zoom: 33%;" />

### Improving

- 提高命中率
- 减少 miss 代价

#### 映射 Block Placement

![image-20240521171627715](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202405211716792.png)

![image-20240521184428283](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202405211844353.png)

??? example "Tag计算"
	![image-20240521184732495](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202405211847562.png)

	**主存中的Block Address = Index + Tag**	
	![image-20240521184749374](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202405211847448.png)

> 前面已经写的比较详细了

#### **Decreasing miss penalty** **with multilevel caches**

 **Add a second level cache:**

- often primary cache is on the same chip as the processor

- **use SRAMs to add another cache above primary memory (DRAM)**

- miss penalty goes down if data is in 2nd level cache

一级和二级的cache关注的目标不同：

- 一级  hit time
- 二级  miss rate

如果第一级的cache失效，就会访问第二级的cache，如果成功，那么第一级的penalty就是第二级的访问时间；...

!!! example "例题"
	![image-20240521190448405](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202405211904480.png)
	![image-20240521193325732](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202405211933797.png)

## **Virtual Memory** 

> **Main Memory act as a “Cache” for the secondary storage.** 
>
> **Translation of a program’s address space to physical address**

**Motivation:** 

- Efficient and safe **sharing of memory** among multiple programs.（多个Va映射到同一个Pa）

- Remove the programming burdens of a small, limited **amount of main memory.** 

<img src="https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202405211911891.png" alt="image-20240521191101834" style="zoom:50%;" />

Larger number of virtual pages than physical pages  现如今不再是这样

### Page faults

**The data is not in memory, retrieve it from disk**

- huge miss penalty, thus pages should be fairly large (e.g., 4KB)
- reducing page faults is important (LRU is worth the price)
- can handle the faults **in software instead of hardware**  Cache是硬件
- using write-through is too expensive so we use **write back**
    同时写到硬盘和主存代价太大

<img src="https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202405211919729.png" alt="image-20240521191908680" style="zoom:50%;" />

### Page Table | 页表

![image-20240521200223719](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202405212002834.png)

> 页表指针

- 在Memory中存储  indexed by the virtual page number
- **Each Entry** in the table contains the **physical page number for that virtual pages if the page is current in memory**
- **Page table, Program counter and the page table register**, specifies the state of the program. Each process has one page table. 
    如果转换进程，要保存当前进程的状态
- 操作系统只分配物理内存地址，不保存页表。
- Each program has its own page table  每一个进程有自己的页表。

操作系统 OS

- When the OS creates a process, it usually **creates the space on disk for all the pages of a process.**
    - When a page fault occurs, the OS will be given control **through exception mechanism.**
    - The OS will find the page in the disk by the page table.
    - **the OS will bring the requested page into main memory. If all the pages in main memory are in use, the OS will use LRU strategy to choose a page to replace**

Virtual Address

- virtual page number

- Page offset

### Page faults

**Write**

- **use write-back strategy. To do so, the machines need add a dirty bit to the entry of page table.** 

- The dirty bit is set when a page is first written. If the dirty bit of a page is set, the page must be written back to disk before being replaced.

### TLB

相当于Page Table的一个cache

![image-20240521201254225](https://zzh-pic-for-self.oss-cn-hangzhou.aliyuncs.com/img/202405212012363.png)
